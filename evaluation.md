# Evaluation

## Experimental Setup
All runs were performed using the same model and configuration,
ensuring that observed differences were caused by prompt design.

## Evaluation Criteria
- Structural consistency
- Relevance
- Repeatability
- Automation readiness

## Comparison

| Criterion            | Prompt A | Prompt B |
|---------------------|----------|----------|
| Structure           | Unstable | Stable   |
| Filler content      | Frequent | Minimal  |
| Repeatability       | Low      | High     |
| Automation-ready    | No       | Yes      |

## Conclusion
Prompt B significantly improved output consistency and comparability
while preserving informational content. Structured prompting reduced
uncontrolled variability and produced automation-ready summaries.
Prompt B was selected due to higher controllability and consistent
output across multiple runs.

